{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK, UNK_CODE = '<UNK>', 0\n",
    "BOS, BOS_CODE = '<BOS>', 1\n",
    "EOS, EOS_CODE = '<EOS>', 2\n",
    "PAD, PAD_CODE = '<PAD>', 3\n",
    "\n",
    "IGNORE = \"()[]{}:<>~@#$%^/\\|_+*…–«»\"\n",
    "AS_DOT = \";\"\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self._tokens_to_words = None\n",
    "        self._words_to_tokens = None\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _update(fdist, path):\n",
    "        with open(path, 'r') as f:\n",
    "            text = f.read()\n",
    "            text = text.replace('\\xa0', ' ').replace('\\ufeff','')\n",
    "            text = text.lower()\n",
    "\n",
    "        for sentence in nltk.tokenize.sent_tokenize(text):\n",
    "            for word in nltk.tokenize.word_tokenize(sentence):\n",
    "                fdist[word]+=1\n",
    "        return fdist               \n",
    "\n",
    "    \n",
    "    def build(self, paths, max_size=30000):\n",
    "        if type(paths) is str:\n",
    "            paths = [paths]\n",
    "\n",
    "        # collect all words\n",
    "        fdist = FreqDist()\n",
    "        for p in paths:\n",
    "            fdist = self._update(fdist, p)\n",
    "            \n",
    "        # build vocab from the most frequent words\n",
    "        most_common = fdist.most_common(max_size)\n",
    "        words       = [ UNK, EOS, BOS, PAD ] + [w for w, _ in most_common]\n",
    "        self._tokens_to_words = words\n",
    "        self._words_to_tokens = {words[i]:i for i in range(len(words))}        \n",
    "\n",
    "        \n",
    "    def save(self, path):\n",
    "        raise NotImplementedError\n",
    "\n",
    "        \n",
    "    def load(self, path):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 39367), ('.', 16451), ('и', 12904), ('–', 10927), ('не', 6534), ('что', 5763), ('в', 5718), ('он', 5544), ('на', 3594), ('она', 3430), ('с', 3327), ('я', 3190), ('как', 2656), ('его', 2574), ('но', 2564), ('?', 2335), ('это', 2220), ('к', 1983), ('ее', 1801), ('все', 1667), ('было', 1654), ('!', 1545), ('так', 1411), ('сказал', 1411), ('а', 1385), ('то', 1384), ('же', 1323), ('ему', 1250), ('о', 1241), ('за', 1139), ('левин', 1134), (';', 1108), ('только', 1016), ('ты', 991), ('у', 913), ('был', 899), ('по', 832), ('когда', 829), ('для', 827), ('сказала', 827), ('бы', 820), ('от', 813), ('да', 806), ('теперь', 805), ('«', 775), ('»', 774), ('вы', 754), ('из', 735), ('была', 728), (':', 706), ('еще', 699), ('ей', 688), ('мне', 675), ('кити', 658), ('они', 644), ('него', 622), ('уже', 600), ('нет', 588), ('очень', 570), ('быть', 560), ('чтобы', 528), ('меня', 524), ('вронский', 508), ('себя', 501), ('этого', 499), ('себе', 499), ('были', 499), ('ни', 496), ('анна', 496), ('если', 493), ('ничего', 481), ('того', 471), ('том', 465), ('ну', 460), ('ней', 441), ('алексей', 429), ('их', 424), ('степан', 423), ('аркадьич', 422), ('чем', 415), ('александрович', 395), ('может', 394), ('вот', 385), ('тем', 380), ('есть', 380), ('надо', 379), ('опять', 375), ('ли', 374), ('или', 369), ('потому', 368), ('время', 365), ('говорил', 357), ('мог', 357), ('будет', 353), ('ним', 352), ('нее', 347), ('мы', 342), ('до', 320), ('руку', 309), ('долли', 300)]\n",
      "['<UNK>', '<EOS>', '<BOS>', '<PAD>', ',', '.', 'и', '–', 'не', 'что', 'в', 'он', 'на', 'она', 'с', 'я', 'как', 'его', 'но', '?', 'это', 'к', 'ее', 'все', 'было', '!', 'так', 'сказал', 'а', 'то', 'же', 'ему', 'о', 'за', 'левин', ';', 'только', 'ты', 'у', 'был', 'по', 'когда', 'для', 'сказала', 'бы', 'от', 'да', 'теперь', '«', '»', 'вы', 'из', 'была', ':', 'еще', 'ей', 'мне', 'кити', 'они', 'него', 'уже', 'нет', 'очень', 'быть', 'чтобы', 'меня', 'вронский', 'себя', 'этого', 'себе', 'были', 'ни', 'анна', 'если', 'ничего', 'того', 'том', 'ну', 'ней', 'алексей', 'их', 'степан', 'аркадьич', 'чем', 'александрович', 'может', 'вот', 'тем', 'есть', 'надо', 'опять', 'ли', 'или', 'потому', 'время', 'говорил', 'мог', 'будет', 'ним', 'нее', 'мы', 'до', 'руку', 'долли']\n",
      "{'потому': 93, 'и': 6, 'ни': 71, 'мы': 100, 'их': 80, '»': 49, 'это': 20, 'аркадьич': 82, 'в': 10, 'что': 9, 'теперь': 47, 'ним': 98, 'ней': 78, '?': 19, 'надо': 89, '!': 25, 'вот': 86, '<PAD>': 3, 'говорил': 95, 'были': 70, 'еще': 54, 'будет': 97, 'за': 33, 'сказал': 27, 'анна': 72, 'тем': 87, 'да': 46, 'он': 11, 'был': 39, 'алексей': 79, 'есть': 88, '–': 7, 'опять': 90, '.': 5, 'или': 92, 'а': 28, 'по': 40, 'она': 13, 'нее': 99, 'может': 85, 'ну': 77, '<EOS>': 1, 'меня': 65, 'ли': 91, 'кити': 57, 'же': 30, 'себе': 69, 'бы': 44, 'очень': 62, 'чем': 83, 'степан': 81, 'время': 94, 'о': 32, 'быть': 63, 'себя': 67, ';': 35, 'они': 58, 'когда': 41, 'как': 16, 'сказала': 43, 'с': 14, '<UNK>': 0, 'у': 38, 'руку': 102, 'левин': 34, 'для': 42, 'него': 59, 'этого': 68, 'не': 8, 'я': 15, 'но': 18, ',': 4, 'долли': 103, 'из': 51, 'только': 36, ':': 53, 'чтобы': 64, '«': 48, 'к': 21, '<BOS>': 2, 'его': 17, 'вы': 50, 'то': 29, 'от': 45, 'на': 12, 'ее': 22, 'было': 24, 'мне': 56, 'вронский': 66, 'ничего': 74, 'все': 23, 'нет': 61, 'александрович': 84, 'ты': 37, 'мог': 96, 'ему': 31, 'того': 75, 'том': 76, 'ей': 55, 'была': 52, 'уже': 60, 'до': 101, 'если': 73, 'так': 26}\n"
     ]
    }
   ],
   "source": [
    "path=\"data/anna.txt\"\n",
    "\n",
    "voc = Vocabulary()\n",
    "voc.build(path, 100)\n",
    "print(voc._tokens_to_words)\n",
    "print(voc._words_to_tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
